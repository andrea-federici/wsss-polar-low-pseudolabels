{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["kX6CCAwaNEJg","sLzsaVo_NKmz","MhNYDmr3RPoU"],"mount_file_id":"1NwjYQuv9OKV-DlQQNgWXC97TeT-jDMI5","authorship_tag":"ABX9TyMne9utJw81PVu7AEnpKHfW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Setup and Settings"],"metadata":{"id":"n8yvKDy0BFxf"}},{"cell_type":"code","source":["if 'google.colab' in str(get_ipython()):\n","    !pip install captum\n","    !pip install pytorch-lightning\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd /content/drive/MyDrive/Thesis/"],"metadata":{"id":"2gpiyoVGTlVS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aac5MCpNeGjV"},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import StratifiedShuffleSplit\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import (\n","    DataLoader,\n","    Subset,\n","    WeightedRandomSampler,\n","    random_split\n",")\n","from torchvision import datasets, transforms\n","import pytorch_lightning as pl\n","from PIL import Image\n","from tqdm import tqdm\n","\n","from models import ConvModel\n","from model_container import ModelContainer"]},{"cell_type":"code","source":["import warnings\n","\n","warnings.filterwarnings('ignore', message='.*DataLoader will create.*') # Suppressed the warning related to the creation of DataLoader using a high number of num_workers"],"metadata":{"id":"354uOteqZls1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SETTINGS\n","\n","num_workers_for_data_loaders = 8 if torch.cuda.is_available() else 6 # 8 should be optimal if GPU is available. 6 should be optimal for CPU."],"metadata":{"id":"N-nsNQPrTHvr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Auxiliary Functions"],"metadata":{"id":"kX6CCAwaNEJg"}},{"cell_type":"code","source":["def show_image(image, title=\"\"):\n","    plt.imshow(image)\n","    plt.title(title)\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"id":"nxw_IFhLNKND"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_targets_and_classes(dataset):\n","    if isinstance(dataset, Subset):\n","        original_dataset = dataset.dataset\n","        subset_indices = dataset.indices\n","        targets = [original_dataset.targets[i] for i in subset_indices]\n","        classes = original_dataset.classes\n","        class_to_idx = dataset.dataset.class_to_idx\n","    else:\n","        targets = dataset.targets\n","        classes = dataset.classes\n","        class_to_idx = dataset.class_to_idx\n","    return targets, classes, class_to_idx"],"metadata":{"id":"LADMlTm2jHsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_dataset_stats(dataset, dataset_name=\"\"):\n","    # Retrive targes, class information, and class-to-index mapping\n","    targets, classes, class_to_idx = get_targets_and_classes(dataset)\n","\n","    # Count the occurrences of each class in the dataset\n","    dataset_counts = Counter(targets)\n","\n","    # Get class indices for 'pos' and 'neg'\n","    pos_idx = class_to_idx['pos']\n","    neg_idx = class_to_idx['neg']\n","\n","    # Get the number of positive and negative samples\n","    pos_count = dataset_counts[pos_idx]\n","    neg_count = dataset_counts[neg_idx]\n","    total_count = len(targets)\n","\n","    # Calculate the class ratio and percentages\n","    class_ratio = pos_count / neg_count if neg_count > 0 else float('inf')\n","    pos_percentage = (pos_count / total_count) * 100\n","    neg_percentage = (neg_count / total_count) * 100\n","\n","    # Print dataset statistics\n","    print(f\"'{dataset_name}' dataset:\")\n","    print(f\"\\tNumber of samples: {total_count} (neg: {neg_count}, pos: {pos_count})\")\n","    print(f\"\\tNumber of classes: {len(classes)}\")\n","    print(f\"\\tClass names: {classes}\")\n","    print(f\"\\tClass distribution ratio (pos:neg): {class_ratio:.2f}\")\n","    print(f\"\\tClass percentages: {pos_percentage:.2f}% pos, {neg_percentage:.2f}% neg\")\n","    print()"],"metadata":{"id":"9hvlXehzaBde"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load and Inspect Data"],"metadata":{"id":"sLzsaVo_NKmz"}},{"cell_type":"code","source":["data_augmentation = transforms.Compose([\n","    transforms.RandomAffine(degrees=45, translate=(0.1, 0.1), fill=0),  # Random Translation and Rotation\n","    transforms.RandomHorizontalFlip(),  # Random Horizontal Flip\n","    transforms.RandomVerticalFlip(),  # Random Vertical Flip\n","    transforms.RandomResizedCrop(size=(512, 512), scale=(0.85, 1.15)),  # Random Zoom and Crop\n","    transforms.ToTensor(),  # Convert to tensor\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Rescaling / Normalizing\n","])\n","\n","data_prep = transforms.Compose([\n","    transforms.CenterCrop(size=(512, 512)),  # Center Crop\n","    transforms.ToTensor(),  # Convert to tensor\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Rescaling / Normalizing\n","])"],"metadata":{"id":"6YvqFdZSq-Ya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dir = 'data/train'\n","test_dir = 'data/test'\n","\n","train_val_data = datasets.ImageFolder(train_dir, transform=data_augmentation)\n","test_data = datasets.ImageFolder(test_dir, transform=data_prep)"],"metadata":{"id":"zXN7m0ajTPZj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","\n","print_dataset_stats(train_val_data, \"Train val\")\n","print_dataset_stats(test_data, \"Test\")"],"metadata":{"id":"Vb81lIJrI9mc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Process Data"],"metadata":{"id":"MhNYDmr3RPoU"}},{"cell_type":"code","source":["split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n","\n","labels = train_val_data.targets\n","\n","# Split the data into training and validation sets while preserving class proportions\n","for train_indices, val_indices in split.split(np.zeros(len(labels)), labels):\n","    print(f\"Number of 'Train' indices: {len(train_indices)}\")\n","    print(f\"Number of 'Val' indices: {len(val_indices)}\")\n","\n","    train_data = Subset(train_val_data, train_indices)\n","\n","    # For the validation data we reload the images so that we don't apply augmentation\n","    val_data = Subset(datasets.ImageFolder(train_dir, transform=data_prep), val_indices)\n","\n","print_dataset_stats(train_data, \"Train\")\n","print_dataset_stats(val_data, \"Val\")\n"],"metadata":{"id":"FdKoOVcB_fUX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.dataset.transform"],"metadata":{"id":"7mlclyTma_HT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_data.dataset.transform"],"metadata":{"id":"5H2oue_wa4xg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create data loader based on class balance (imbalance)\n","\n","train_counts = Counter([train_val_data.targets[i] for i in train_indices])\n","\n","class_weights_not_normalized = { cls: 1.0 / count for cls, count in train_counts.items() }\n","total_weights = sum(class_weights_not_normalized.values())\n","class_weights = { cls: weight / total_weights for cls, weight in class_weights_not_normalized.items() }\n","print(\"Class weights:\")\n","print(class_weights)\n","\n","sample_weights = [class_weights[train_val_data.targets[i]] for i in train_indices] # Assigns the corresponding weight to each sample in the train dataset\n","\n","sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n","\n","# Create DataLoader for training data using the sampler\n","train_loader = DataLoader(train_data, batch_size=64, sampler=sampler, num_workers=num_workers_for_data_loaders)\n","\n","# Create DataLoader for validation data without any sampler\n","val_loader = DataLoader(val_data, batch_size=64, shuffle=False, num_workers=num_workers_for_data_loaders)"],"metadata":{"id":"dEtpEyVTRRDS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Build and Train Model"],"metadata":{"id":"ySwg1NjNfKiZ"}},{"cell_type":"code","source":["# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"],"metadata":{"id":"KGB80Gu1biby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ConvModel();\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","lit_model = ModelContainer(model, criterion, optimizer)"],"metadata":{"id":"Qsi0W5BKVPyL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stopping_callback = pl.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    mode='min',\n","    patience=5\n",")\n","\n","checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","    monitor='val_loss',\n","    mode='min',\n","    save_top_k=1,\n","    dirpath='checkpoints/',\n","    filename='best-checkpoint'\n",")"],"metadata":{"id":"CuFn1af7IB5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = pl.Trainer(\n","    max_epochs = 100,\n","    callbacks=[early_stopping_callback, checkpoint_callback],\n","    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n","    devices=1,\n","    check_val_every_n_epoch=1\n",")"],"metadata":{"id":"M7GsU7gbwM_u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.fit(lit_model, train_loader, val_loader)"],"metadata":{"id":"q-dHBixUwwWM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot training and validation loss over epochs\n","plt.plot(lit_model.train_losses, label='Train Loss')\n","plt.plot(lit_model.val_losses, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss over Epochs')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"-6uNV_9Ow1XS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Save and Load Model"],"metadata":{"id":"X1l3gJ_wDYh0"}},{"cell_type":"code","source":["# Load the best model\n","model = ModelContainer.load_from_checkpoint('checkpoints/best-checkpoint.ckpt', model=ConvModel(), criterion=criterion, optimizer=optimizer)"],"metadata":{"id":"rWrQhmYlVNpX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Evaluation"],"metadata":{"id":"2unp9nwtDeMl"}},{"cell_type":"code","source":["pos_images = os.listdir(os.path.join(train_dir, 'pos')) # Directory of 'pos' images\n","neg_images = os.listdir(os.path.join(train_dir, 'neg')) # Directory of 'neg' images\n","\n","# Pick random image\n","category = random.choice(['pos', 'neg'])\n","chosen_image = random.choice(os.listdir(os.path.join(train_dir, category)))\n","image_path = os.path.join(train_dir, category, chosen_image)\n","\n","# Create and overlay heatmap\n","original_image = Image.open(image_path).convert('RGB')\n","transformed_image = data_prep(original_image).unsqueeze(0)\n","heatmap = model.generate_gradcam_heatmap(transformed_image)\n","overlayed_image = model.overlay_gradcam_heatmap(original_image, heatmap)\n","\n","\n","# Display image with and without heatmap\n","\n","plt.figure(figsize=(12, 6))\n","\n","# Original image (left)\n","plt.subplot(1, 2, 1)\n","plt.imshow(original_image)\n","plt.title('Original Image')\n","plt.axis('off')\n","\n","# Image with heatmap (right)\n","plt.subplot(1, 2, 2)\n","plt.imshow(overlayed_image)\n","plt.title('Grad-CAM Overlay')\n","plt.axis('off')\n","\n","plt.show()\n","\n","\n","# Print additional info\n","\n","print(f'Image path: {image_path}') # Print image path\n","\n","pred = torch.argmax(model(transformed_image.to(device)), dim=1).item()\n","print(f'Predicted: {\"pos\" if pred==1 else \"neg\"}. Actual: {category}')"],"metadata":{"id":"4VkXmmnDdkZL"},"execution_count":null,"outputs":[]}]}