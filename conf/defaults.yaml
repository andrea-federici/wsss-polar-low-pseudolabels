## HARDWARE ##
hardware:
  device: cuda
  accelerator: gpu
  devices: 1

## LOGGER ##
neptune:
  project: 'andreaf/polarlows'
  api_key: ${oc.env:NEPTUNE_API_TOKEN}

## DATA ##
data:
  directory: data/polar_lows
  original_width: 800
  original_height: 800

## TRANSFORMS ##
transforms:
  resize_width: 512
  resize_height: 512

  normalization:
    mean: [0.2872, 0.2872, 0.4595]
    std: [0.1806, 0.1806, 0.2621]

# This augmentation is used only if train_data_transform is set to 'train' in the 
# training mode
  augmentation:
    translate_frac: 0.4 # Using Optuna, the best value was found to be 0.4113, 
                               # (with degrees: 20, scale: [0.9, 1.1])
    degrees: 45
    scale: [0.9, 1.1]
    horizontal_flip: true
    vertical_flip: true

## MISC ##
# Enable Tensor Cores for faster matrix multiplications, trading some 
# precision for performance.
# - 'high' gives the best speed-up but with reduced precision.
# - 'medium' balances precision and performance.
# - 'highest' (default) maintains full precision but may be slower.
matmul_precision: medium
num_workers: 16

## MODEL ##
torch_model: xception
num_classes: 2

## LOSS AND OPTIMIZER ##
criterion: cross_entropy
optimizer: adam

## TRAINING ##
batch_size: 16
max_epochs: 200
learning_rate: 5e-4

## CALLBACKS ##

# Early stopping
early_stopping:
  monitor: val_loss
  mode: min
  patience: 25

# Checkpoint
checkpoint:
  monitor: val_loss
  mode: min
  directory: out/checkpoints
  filename: best-checkpoint

# Learning rate scheduler
lr_scheduler:
  name: reduce_lr_on_plateau
  monitor: val_loss
  mode: min
  patience: 7
  factor: 0.5